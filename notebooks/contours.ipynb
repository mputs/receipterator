{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b805dc-39ef-4745-995e-fbd5ae998659",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from math import pi\n",
    "from scipy.stats import linregress\n",
    "from math import pi\n",
    "from scipy.optimize import minimize\n",
    "import time\n",
    "\n",
    "\n",
    "# bonnetje Plus (Marco)\n",
    "filename = \"IMG_0131.jpg\"\n",
    "img1 = np.array(Image.open(filename))\n",
    "imgbw = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "plt.imshow(imgbw, cmap=\"gray\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9711f49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bonnetje Jumbo (Martijn)\n",
    "filename = \"IMG_0090.jpg\"\n",
    "img1 = np.array(Image.open(filename))\n",
    "imgbw = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "plt.imshow(imgbw, cmap=\"gray\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f328e688-0dab-4960-821b-6ad145e586be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# blur the image\n",
    "blurred = cv2.GaussianBlur(imgbw,(101,101),0)\n",
    "plt.imshow(blurred, cmap=\"gray\")\n",
    "plt.show()\n",
    "# compute the gradient\n",
    "sobelx = cv2.Sobel(blurred,cv2.CV_64F,1,0,ksize=1)\n",
    "sobely = cv2.Sobel(blurred,cv2.CV_64F,0,1,ksize=1)\n",
    "fig,axs = plt.subplots(1,2)\n",
    "axs[0].imshow(sobelx, cmap=\"gray\")\n",
    "axs[1].imshow(sobely, cmap=\"gray\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56258556-91f3-423d-b11e-f2355023de7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def venergy(gradx, x1, x2, direction, alpha=.5, beta=1, max_iter = 10000, DEBUG=False):\n",
    "    #parameters:\n",
    "    # gradx: gradient in horizontal direction\n",
    "    # cpoints: x-values for the initial points to look at. first point is at the top, second at the bottom\n",
    "    # direction: indicating if we look from right to left (direction = -1) or from left to right (direction = 1)\n",
    "    # alpna: weight for the directional part\n",
    "    # beta: weight for the gradient\n",
    "    # max_iter: maximum number of iterations\n",
    "    \n",
    "    h = gradx.shape[0]\n",
    "    w = gradx.shape[1]\n",
    "    sum_x = h * (h + 1) // 2               \n",
    "    sum_x2 = h * (h + 1) * (2 * h + 1) // 6\n",
    "    denominator = h * sum_x2 - sum_x**2\n",
    "\n",
    "    x1 = float(x1)\n",
    "    x2 = float(x2)\n",
    "\n",
    "    epsilon = 1e-3\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        Y = np.arange(0,gradx.shape[0],1)\n",
    "        #determine the direction of the line and assign X\n",
    "        b = x1;\n",
    "        a = (x2-x1)/Y[-1]\n",
    "        X = (a*Y+b).astype(\"int32\")\n",
    "        grad = gradx[Y,X]\n",
    "        \n",
    "        # fit a line through the gradient and estimate the values at the two control points\n",
    "        # the external energy is -gradient at control points (=l.intercept + l.slope*y)\n",
    "        # the internal energy is forcing the line in a certain direction\n",
    "        sum_y = grad.sum()                          \n",
    "        sum_xy = (Y*grad).sum() \n",
    "        slope = (h * sum_xy - sum_x * sum_y) / denominator\n",
    "        intercept = (sum_y * sum_x2 - sum_x * sum_xy) / denominator       \n",
    "        x1_delta = -intercept + direction*alpha\n",
    "        x2_delta = -(intercept + slope*Y[-1]) + direction*alpha        \n",
    "        # move the line\n",
    "        x1 += x1_delta\n",
    "        x2 += x2_delta\n",
    "        delta = np.abs(x1_delta) + np.abs(x2_delta)\n",
    "        if delta < epsilon:\n",
    "            break\n",
    "    if DEBUG: \n",
    "        print(f\"contour found after {i} iterations (delta = {delta})\");\n",
    "    return (x1,x2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aad0510-c17c-44fa-ba57-5eab24b6f00b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "t = time.time()\n",
    "(r1, r2) = venergy(sobelx, 3000,3000, -1, DEBUG=True)\n",
    "(l1, l2) = venergy(sobelx, 10,10, 1, max_iter = 6000, DEBUG=True)\n",
    "print(f\"time elapsed: {time.time()-t}\")\n",
    "m1 = (r1+l1)/2\n",
    "m2 = (r2+l2)/2\n",
    "\n",
    "angle = 180*np.arctan2(m2-m1, sobelx.shape[0])/pi\n",
    "\n",
    "def rotateback(m1, m2):\n",
    "    Cx = imgbw.shape[1]//2; Cy =imgbw.shape[0]//2;\n",
    "\n",
    "    c = np.array([Cx,Cy])\n",
    "    p1 = np.array([m1, 0])\n",
    "    p2 = np.array([m2, imgbw.shape[0]])\n",
    "\n",
    "    d = np.linalg.norm(np.cross(p2-p1, p1-c))/np.linalg.norm(p2-p1)\n",
    "    orientation = np.sign(np.cross(p1-c, p2-c))\n",
    "    return d*orientation + Cx\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223203ec-b8b2-4ab4-9ef6-aceefb8686eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.imshow(imgbw, cmap=\"gray\")\n",
    "plt.plot([r1,r2], [0, imgbw.shape[0]],color=\"red\")\n",
    "plt.plot([l1,l2], [0, imgbw.shape[0]],color=\"red\")\n",
    "plt.plot([m1, m2], [0, imgbw.shape[0]], color = \"blue\", alpha = .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa166a9-8d18-4e3c-8785-5a77dbdacf25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Cx = imgbw.shape[1]//2; Cy =imgbw.shape[0]//2;\n",
    "w = imgbw.shape[1]; h = imgbw.shape[0];\n",
    "M = cv2.getRotationMatrix2D((Cx, Cy), -angle, 1.0)\n",
    "rotated = cv2.warpAffine(imgbw, M, (img1.shape[1], img1.shape[0]))\n",
    "cropl = rotateback(l1, l2)\n",
    "cropr = rotateback(r1, r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60fedfe-1749-43e5-9bab-ec426d5d93ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cropped = rotated[:,int(cropl):int(cropr)]\n",
    "plt.imshow(cropped, cmap=\"gray\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77395c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prop_letter_resolution(image, max_letters=48):\n",
    "    #parameters:\n",
    "    # image: image\n",
    "    # max_letters: number of letters (content size) that would fit horizontally (supermarket-dependent)\n",
    "    #  48 is measured with a rule of thumb using the PLUS receipt IMG_0131.jpg.\n",
    "    \n",
    "    # Horizontal resolution\n",
    "    res = np.shape(image)[0]\n",
    "    \n",
    "    # Dots per letter\n",
    "    dpl = res / max_letters\n",
    "    return dpl\n",
    "    \n",
    "prop_letter_resolution(cropped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1959c2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prop_sharpness(image):\n",
    "    #parameters:\n",
    "    # image: image\n",
    "    #source: https://stackoverflow.com/a/26014796\n",
    "    \n",
    "    gy, gx = np.gradient(image)\n",
    "    gnorm = np.sqrt(gx**2 + gy**2)\n",
    "    sharpness = np.average(gnorm)\n",
    "    return sharpness\n",
    "    \n",
    "prop_sharpness(cropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b515031d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prop_contrast_ratio(image):\n",
    "    #parameters:\n",
    "    # image: image\n",
    "    \n",
    "    L1 = np.percentile(image, 10) / 255\n",
    "    L2 = np.percentile(image, 90) / 255\n",
    "    # the 10 and 90 percentiles as a more robust (?) variant than min max\n",
    "    \n",
    "    CR = (L1 + 0.05) / (L2 + 0.05)\n",
    "    return CR\n",
    "    \n",
    "prop_contrast_ratio(cropped)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0cb008-656a-401e-a876-f78aacdc0634",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def automatic_brightness_and_contrast(image, clip_hist_percent=25):\n",
    "\n",
    "    # Calculate grayscale histogram\n",
    "    hist = cv2.calcHist([image],[0],None,[256],[0,256])\n",
    "    hist_size = len(hist)\n",
    "\n",
    "    # Calculate cumulative distribution from the histogram\n",
    "    accumulator = []\n",
    "    accumulator.append(float(hist[0]))\n",
    "    for index in range(1, hist_size):\n",
    "        accumulator.append(accumulator[index -1] + float(hist[index]))\n",
    "\n",
    "    # Locate points to clip\n",
    "    maximum = accumulator[-1]\n",
    "    clip_hist_percent *= (maximum/100.0)\n",
    "    clip_hist_percent /= 2.0\n",
    "\n",
    "    # Locate left cut\n",
    "    minimum_gray = 0\n",
    "    while accumulator[minimum_gray] < clip_hist_percent:\n",
    "        minimum_gray += 1\n",
    "\n",
    "    # Locate right cut\n",
    "    maximum_gray = hist_size -1\n",
    "    while accumulator[maximum_gray] >= (maximum - clip_hist_percent):\n",
    "        maximum_gray -= 1\n",
    "\n",
    "    # Calculate alpha and beta values\n",
    "    alpha = 255 / (maximum_gray - minimum_gray)\n",
    "    beta = -minimum_gray * alpha\n",
    "\n",
    "    '''\n",
    "    # Calculate new histogram with desired range and show histogram \n",
    "    new_hist = cv2.calcHist([gray],[0],None,[256],[minimum_gray,maximum_gray])\n",
    "    plt.plot(hist)\n",
    "    plt.plot(new_hist)\n",
    "    plt.xlim([0,256])\n",
    "    plt.show()\n",
    "    '''\n",
    "\n",
    "    auto_result = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)\n",
    "    return (auto_result, alpha, beta)\n",
    "\n",
    "adj, alpha, beta = automatic_brightness_and_contrast(cropped)\n",
    "plt.imshow(adj, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8178cbf2-21ff-4daa-af9f-31cd10dec994",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_adj = pytesseract.image_to_string(adj)\n",
    "print(text_adj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff48d056",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(text, to_lower_case = True):\n",
    "    lns = str.splitlines(text_adj)\n",
    "    bag = []\n",
    "    for ln in lns:\n",
    "        bag = bag + ln.split()\n",
    "    bag_unique = list(set(bag))\n",
    "    if to_lower_case:\n",
    "        bag_unique = [str.lower(x) for x in bag_unique]\n",
    "    return bag_unique\n",
    "                     \n",
    "bag = bag_of_words(text_adj)\n",
    "bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca2e94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source https://www.geeksforgeeks.org/damerau-levenshtein-distance/\n",
    "# method = Damerauâ€“Levenshtein (this method is also used in R package stringdist (Mark vd Loo))\n",
    "def optimal_string_alignment_distance(s1, s2):\n",
    "    # Create a table to store the results of subproblems\n",
    "    dp = [[0 for j in range(len(s2)+1)] for i in range(len(s1)+1)]\n",
    "     \n",
    "    # Initialize the table\n",
    "    for i in range(len(s1)+1):\n",
    "        dp[i][0] = i\n",
    "    for j in range(len(s2)+1):\n",
    "        dp[0][j] = j\n",
    " \n",
    "    # Populate the table using dynamic programming\n",
    "    for i in range(1, len(s1)+1):\n",
    "        for j in range(1, len(s2)+1):\n",
    "            if s1[i-1] == s2[j-1]:\n",
    "                dp[i][j] = dp[i-1][j-1]\n",
    "            else:\n",
    "                dp[i][j] = 1 + min(dp[i-1][j], dp[i][j-1], dp[i-1][j-1])\n",
    " \n",
    "    # Return the edit distance\n",
    "    return dp[len(s1)][len(s2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3f8d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_dist_common_words(words_bag, words_common):\n",
    "\n",
    "    words_bag = bag\n",
    "    words_common = ['omschrijving','bedrag','totaal']\n",
    "\n",
    "    dm = [[ optimal_string_alignment_distance(a, b) for b in words_bag] for a in words_common]\n",
    "\n",
    "    # max scores\n",
    "    s = [np.min(d) for d in dm]\n",
    "\n",
    "    # which\n",
    "    w = [np.argmin(d) for d in dm]\n",
    "\n",
    "\n",
    "    # matched words\n",
    "    matches = [words_bag[i] for i in w]\n",
    "\n",
    "    return (s,matches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e2d575",
   "metadata": {},
   "outputs": [],
   "source": [
    "common = ['omschrijving','bedrag','totaal']\n",
    "str_dist_common_words(bag, common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627ded9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed81e89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "renv_kernel",
   "language": "python",
   "name": "renv_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
